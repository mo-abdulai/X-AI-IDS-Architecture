{"cells":[{"cell_type":"markdown","id":"619992d4","metadata":{"id":"619992d4"},"source":["# XAI MODEL BUILD"]},{"cell_type":"code","execution_count":1,"id":"VDFjNCGEjgFG","metadata":{"id":"VDFjNCGEjgFG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749064255134,"user_tz":240,"elapsed":21299,"user":{"displayName":"Mohammed Abdulai","userId":"11172900894836621933"}},"outputId":"ddf7f95b-3737-434c-ec97-86fc3aab9720"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"3cca1b0c","metadata":{"id":"3cca1b0c"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"id":"872fa7f5","metadata":{"id":"872fa7f5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"52e1e658-4807-4583-e1bf-a9fde8d09274"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.15.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.5.26)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=7e089be3cab868b7d988dc90cfefb7cc658707c2a4914d78b03c943f73783f6c\n","  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n","Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"]}],"source":["!pip install lime\n","!pip install shap\n","\n","import pandas as pd\n","import numpy as np\n","import joblib\n","import shap\n","import lime.lime_tabular\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import time\n","import psutil\n","from tensorflow.keras.models import load_model\n","\n","df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/XAI IDS Architecture/2_Modeling-Phase/train_and_test_datasets/CICIDS-2017/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/XAI IDS Architecture/2_Modeling-Phase/train_and_test_datasets/CICIDS-2017/test.csv')\n","\n","X_train = df_train.drop(['Label'], axis=1)  # Features\n","y_train = df_train['Label']  # Target variable\n","\n","X_test = df_test.drop(['Label'], axis=1)  # Features\n","y_test = df_test['Label']  # Target variable\n","\n","\n","# load the trained model to a specific folder\n","model_folder = \"/content/drive/MyDrive/Colab Notebooks/XAI IDS Architecture/3_Post-Modeling-Phase/Trained_ML_models/Models_CICIDS-2017/\"\n","model_filename = \"CICIDS-2017_DNN.h5\"\n","model_path = model_folder + model_filename\n","\n","model = load_model(model_path)"]},{"cell_type":"markdown","id":"987b058f","metadata":{"id":"987b058f"},"source":["# Explainability Models"]},{"cell_type":"markdown","id":"ee03f3ba","metadata":{"id":"ee03f3ba"},"source":["# SHAP Interpretability"]},{"cell_type":"code","execution_count":null,"id":"d87b31d7","metadata":{"id":"d87b31d7"},"outputs":[],"source":["import shap\n","import psutil\n","import tracemalloc\n","import time\n","import joblib\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","shap.initjs()\n","\n","X_test = pd.DataFrame(X_test, columns=X_train.columns)\n","X_test = X_test.astype(X_train.dtypes)\n","\n","\n","cpu_usage_before = psutil.cpu_percent(interval=1)\n","disk_io_before = psutil.disk_io_counters().write_bytes\n","start_time_shap = time.time()\n","tracemalloc.start()\n","\n","\n","sample_size = min(500, len(X_test))\n","X_test_sample = X_test.sample(sample_size, random_state=42)\n","\n","X_test_sample_array = X_test_sample.to_numpy().astype(np.float32)\n","\n","\n","explainer = shap.DeepExplainer(model, X_test_sample_array[:50])  # Background dataset\n","shap_values = explainer(X_test_sample_array[:500])\n","\n","\n","end_time_shap = time.time()\n","current_memory_shap, peak_memory_shap = tracemalloc.get_traced_memory()\n","tracemalloc.stop()\n","cpu_usage_after = psutil.cpu_percent(interval=1)\n","disk_io_after = psutil.disk_io_counters().write_bytes\n","\n","\n","execution_time_shap = end_time_shap - start_time_shap\n","memory_used_shap = (peak_memory_shap - current_memory_shap) / (1024 * 1024)  # Convert to MB\n","cpu_usage_change_shap = cpu_usage_after - cpu_usage_before  # Compute CPU usage difference\n","disk_io_used_shap = (disk_io_after - disk_io_before) / (1024 * 1024)  # Convert to MB\n","\n","\n","print(\"\\n **SHAP Computational Overhead Report** ðŸ”¹\")\n","print(f\"**Execution Time:** {execution_time_shap:.4f} seconds\")\n","print(f\"**Peak Memory Usage:** {memory_used_shap:.2f} MB\")\n","print(f\"**CPU Usage Change:** {cpu_usage_change_shap:.2f}%\")\n","print(f\"**Disk I/O Usage:** {disk_io_used_shap:.2f} MB\")\n"]},{"cell_type":"code","execution_count":null,"id":"BeiDndz0bsX4","metadata":{"id":"BeiDndz0bsX4"},"outputs":[],"source":["encoder_path = \"/content/drive/MyDrive/Colab Notebooks/XAI IDS Architecture/2_Modeling-Phase/train_and_test_datasets/CICIDS-2017/label_encoder.pkl\"\n","label_encoder = joblib.load(encoder_path)\n","\n","actual_class_names = label_encoder.classes_\n","print(actual_class_names)"]},{"cell_type":"code","execution_count":null,"id":"Ut-zCSUNw1of","metadata":{"id":"Ut-zCSUNw1of"},"outputs":[],"source":["import shap\n","import matplotlib.pyplot as plt\n","\n","class_idx = 0\n","\n","shap_values_class = shap_values.values[:, :, class_idx]\n","X_test_df = pd.DataFrame(X_test_sample, columns=X_train.columns)\n","\n","\n","# plt.figure(figsize=(12, 6))\n","shap.summary_plot(shap_values_class, X_test_df, plot_type=\"dot\", feature_names=X_test_df.columns)\n","# plt.title(f\"SHAP Global Beeswarm Plot - Class {class_idx} Feature Importance\")\n","# plt.show()\n"]},{"cell_type":"markdown","id":"63524d32","metadata":{"id":"63524d32"},"source":["# EVALUATION METRICS"]},{"cell_type":"markdown","id":"99f6d230","metadata":{"id":"99f6d230"},"source":["# SHAP LEQ and GEU"]},{"cell_type":"code","execution_count":null,"id":"ef608a1d","metadata":{"id":"ef608a1d"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import spearmanr\n","\n","# Functions for Metrics\n","def calculate_local_explanation_quality(predicted_explanations, actual_model_outputs):\n","    \"\"\"\n","    Calculate the Local Explanation Quality (Fidelity Local).\n","\n","    Args:\n","        predicted_explanations (np.ndarray): Predicted explanation outputs (e.g., SHAP predicted values).\n","        actual_model_outputs (np.ndarray): Actual local model outputs.\n","\n","    Returns:\n","        float: Local explanation quality score.\n","    \"\"\"\n","    rmse = np.sqrt(np.mean((predicted_explanations - actual_model_outputs) ** 2))\n","    fidelity_local = 1 - rmse\n","    return fidelity_local\n","\n","def calculate_global_explanation_quality(feature_importance_values, domain_importance_values):\n","    \"\"\"\n","    Calculate the Global Explanation Utility using Spearman's Rank Correlation.\n","\n","    Args:\n","        feature_importance_values (np.ndarray): Feature importance values (e.g., SHAP feature importance).\n","        domain_importance_values (np.ndarray): Domain knowledge importance values.\n","\n","    Returns:\n","        float: Spearman's Rank Correlation.\n","    \"\"\"\n","    if len(feature_importance_values) != len(domain_importance_values):\n","        raise ValueError(\"The number of domain importance scores must match the number of SHAP features.\")\n","    correlation, _ = spearmanr(feature_importance_values, domain_importance_values)\n","    return correlation"]},{"cell_type":"markdown","id":"8190aec6","metadata":{"id":"8190aec6"},"source":["## 1. SHAP Local Explanation Quality (LEQ) (Fidelity)"]},{"cell_type":"code","execution_count":null,"id":"4cfbcdd1","metadata":{"id":"4cfbcdd1","scrolled":true},"outputs":[],"source":["# shap_class_values = shap_values[class_idx]  # Shape: (500, num_features)\n","\n","\n","# base_class_values = explainer.expected_value[class_idx]  # Scalar\n","\n","# shap_reconstructed = shap_class_values.sum(axis=1) + base_class_values\n","\n","\n","class_idx = 0\n","\n","shap_class_values = shap_values.values[:, :, class_idx]  # (500, 15)\n","base_class_value = explainer.expected_value[class_idx]   # scalar\n","\n","shap_reconstructed = shap_class_values.sum(axis=1) + base_class_value\n","\n","\n","# Get actual model probabilities\n","actual_model_outputs = model.predict(X_test_sample)[:, class_idx]  # Shape: (samples,)\n","\n","# Compute fidelity\n","local_quality = calculate_local_explanation_quality(shap_reconstructed, actual_model_outputs)\n","\n","print(f\"âœ… SHAP Local Explanation Quality (Fidelity Local) for Class {class_idx}: {local_quality:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"8Aik1l4tD50-","metadata":{"id":"8Aik1l4tD50-"},"outputs":[],"source":["# Introduce tiny noise\n","shap_reconstructed_noisy = shap_reconstructed + np.random.normal(0, 0.01, size=shap_reconstructed.shape)\n","\n","# Recompute fidelity\n","fidelity_noisy = calculate_local_explanation_quality(shap_reconstructed_noisy, actual_model_outputs)\n","print(f\"Sanity Check Fidelity (with noise): {fidelity_noisy:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"sX9JH-kI_w8k","metadata":{"id":"sX9JH-kI_w8k"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","for class_idx in range(shap_values.values.shape[2]):\n","    shap_class_values = shap_values.values[:, :, class_idx]\n","    base_class_values = explainer.expected_value[class_idx]\n","    shap_reconstructed = shap_class_values.sum(axis=1) + base_class_values\n","    N = len(shap_reconstructed)\n","    actual_outputs = model.predict(X_test_sample)[:, class_idx]\n","    fidelity = 1 - np.sqrt(np.mean((shap_reconstructed - actual_outputs) ** 2)) / N\n","    print(f\"Class {class_idx} Fidelity: {fidelity:.4f}\")\n","\n","\n","plt.figure(figsize=(8, 4))\n","plt.plot(shap_reconstructed, label=\"SHAP Reconstructed\")\n","plt.plot(actual_outputs, label=\"Model Output\", linestyle='--')\n","plt.legend()\n","plt.title(f\"SHAP Approximation vs Model Output (Class {class_idx})\")\n","plt.xlabel(\"Sample Index\")\n","plt.ylabel(\"Probability\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"ae6f3e22","metadata":{"id":"ae6f3e22"},"source":["# SHAP Global Explanation Utility\n"]},{"cell_type":"code","execution_count":null,"id":"52ac9a9e","metadata":{"id":"52ac9a9e"},"outputs":[],"source":["shap_feature_importance = np.abs(shap_values.values).mean(axis=(0, 2))\n","\n","\n","if len(shap_feature_importance) != X_test.shape[1]:\n","    raise ValueError(f\" SHAP feature count ({len(shap_feature_importance)}) does not match dataset feature count ({X_test.shape[1]}).\")\n","\n","# # âœ… Print SHAP Feature Importance Scores\n","# print(\"âœ… SHAP Feature Importances (Mean Absolute Values):\")\n","# for feature, importance in zip(X_test.columns, shap_feature_importance):\n","#     print(f\"{feature}: {importance:.6f}\")\n","\n","# Define expert knowledge importance scores for 18 features\n","expert_importance_scores = np.array([\n","    0.1, 0.9, 0.0, 0.9, 0.1, 0.4, 0.2, 0.2, 0.1, 0.1,\n","    0.05, 0.05, 0.03, 0.02, 0.01  # 18 values\n","])\n","\n","# Ensure expert scores match SHAP feature count\n","if len(expert_importance_scores) != len(shap_feature_importance):\n","    raise ValueError(\" Mismatch: Expert domain scores must match SHAP feature count.\")\n","\n","# Compute Spearmanâ€™s Rank Correlation\n","global_explanation_quality = calculate_global_explanation_quality(\n","    shap_feature_importance, expert_importance_scores\n",")\n","\n","# Print result\n","print(f\" SHAP Global Explanation Quality (Spearmanâ€™s Rank Correlation): {global_explanation_quality:.4f}\")"]},{"cell_type":"markdown","id":"Qj9d0Wp62Hcg","metadata":{"id":"Qj9d0Wp62Hcg"},"source":["## LLM Explainability Of SHAP"]},{"cell_type":"code","execution_count":null,"id":"6ePSazJspyK7","metadata":{"id":"6ePSazJspyK7"},"outputs":[],"source":["import os\n","import openai\n","\n","from google.colab import userdata\n","\n","# openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n","client = openai.OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n","instance_index = 0\n","class_index = 1  # Choose a meaningful class (e.g. \"DoS Hulk\")\n","\n","# SHAP values for instance and class\n","shap_vals = shap_values.values[instance_index, :, class_index]\n","base_val = float(explainer.expected_value[class_index])\n","features = X_test.iloc[instance_index].to_dict()\n","\n","# Build a readable table-like string\n","shap_feature_str = \"\\n\".join([f\"- {k}: value = {v}, SHAP = {round(s, 4)}\"\n","                              for (k, v, s) in zip(features.keys(), features.values(), shap_vals)])\n","\n","\n","shap_description_prompt = f\"\"\"\n","The following is a SHAP explanation for a neural network's prediction of a network traffic sample.\n","\n","Predicted Class: {label_encoder.classes_[class_index]}\n","Base Value (average model output for this class): {round(base_val, 4)}\n","\n","Feature contributions:\n","{shap_feature_str}\n","\n","Explain this prediction in plain English for a network security analyst. Highlight the most influential features and suggest actionable insights.\n","\"\"\"\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": shap_description_prompt}\n","    ],\n","    max_tokens=400,\n","    temperature=0.7\n",")\n","\n","print(\"Plain English Explanation\")\n","print(response.choices[0].message.content)\n","\n"]},{"cell_type":"markdown","id":"Xk1tny402pyk","metadata":{"id":"Xk1tny402pyk"},"source":["# Waterfall Plot"]},{"cell_type":"code","execution_count":null,"id":"YWbPUVlw2rSM","metadata":{"id":"YWbPUVlw2rSM"},"outputs":[],"source":["instance_index = 0\n","class_index = 1\n","\n","# Get SHAP values for the specific instance and class\n","shap_vals = shap_values.values[instance_index, :, class_index]\n","features = X_test_sample.iloc[instance_index].values\n","feature_names = X_test_sample.columns.tolist()\n","\n","# Get model prediction for this instance and class\n","model_probs = model.predict(X_test_sample.iloc[[instance_index]])\n","predicted_prob = model_probs[0, class_index]\n","\n","# Compute base value using SHAP additivity\n","base_val = predicted_prob - shap_vals.sum()\n","\n","# Ensure base_val is a clean float\n","base_val = float(base_val)\n","\n","# Create the SHAP Explanation object\n","shap_explanation = shap.Explanation(\n","    values=shap_vals,\n","    base_values=base_val,\n","    data=features,\n","    feature_names=feature_names\n",")\n","\n","# Plot the waterfall chart\n","shap.plots.waterfall(shap_explanation)"]},{"cell_type":"markdown","id":"83eb9db4","metadata":{"id":"83eb9db4"},"source":["## LIME EXPLAINABILITY"]},{"cell_type":"code","execution_count":null,"id":"704de77a","metadata":{"id":"704de77a"},"outputs":[],"source":["import time\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from lime.lime_tabular import LimeTabularExplainer\n","\n","def explain_with_lime(model, X_test, feature_names, instance_index=0, class_names=None):\n","    \"\"\"\n","    Use LIME to generate an explanation for a model's prediction.\n","\n","    Parameters:\n","    - model: Trained model to explain.\n","    - X_test: Test dataset (features only).\n","    - feature_names: List of feature names.\n","    - instance_index: Index of the instance to explain.\n","    - class_names: List of actual class names (from LabelEncoder).\n","    \"\"\"\n","    # âœ… Initialize LIME explainer\n","    explainer = LimeTabularExplainer(\n","        X_test.values,  # Use raw values\n","        mode=\"classification\",\n","        feature_names=feature_names,\n","        class_names=class_names,\n","        discretize_continuous=True\n","    )\n","\n","\n","    instance = X_test.iloc[[instance_index]].values  # Keep as 2D array\n","\n","\n","    cpu_start = time.process_time()\n","    wall_start = time.time()\n","\n","\n","    explanation = explainer.explain_instance(\n","        instance[0],  # Flatten instance\n","        lambda x: model.predict(pd.DataFrame(x, columns=feature_names)),  # Fix model input\n","        num_features=len(feature_names)\n","    )\n","\n","\n","    cpu_end = time.process_time()\n","    wall_end = time.time()\n","\n","\n","    cpu_time = cpu_end - cpu_start\n","    wall_time = wall_end - wall_start\n","\n","\n","    print(f\"\\nâœ… **LIME Computational Cost Report**\")\n","    print(f\"âœ… CPU Time: {cpu_time:.4f} seconds\")\n","    print(f\"âœ… Wall Time: {wall_time:.4f} seconds\")\n","\n","\n","    explanation.show_in_notebook(show_table=True, show_all=True)\n","\n","    return explanation\n"]},{"cell_type":"code","execution_count":null,"id":"e0efe05d","metadata":{"collapsed":true,"id":"e0efe05d"},"outputs":[],"source":["actual_class_names = list(label_encoder.classes_)\n","\n","\n","lime_explanation = explain_with_lime(\n","    model=model,\n","    X_test=X_test_sample,\n","    feature_names=X_test_sample.columns.tolist(),\n","    instance_index=2,\n","    class_names=actual_class_names\n",")"]},{"cell_type":"code","execution_count":null,"id":"mqr-k-4FJr7D","metadata":{"id":"mqr-k-4FJr7D","collapsed":true},"outputs":[],"source":["import numpy as np\n","\n","# âœ… Get actual model outputs (true probabilities for Class 1)\n","actual_model_outputs = model.predict(X_test_sample)[:, 1]\n","\n","# âœ… Initialize array to store LIME predicted explanations\n","lime_predicted_explanations = np.zeros_like(actual_model_outputs)\n","\n","# âœ… Compute LIME explanations for each instance silently\n","for i in range(len(X_test_sample)):\n","    lime_exp = explain_with_lime(\n","        model=model,\n","        X_test=X_test_sample,\n","        feature_names=X_test_sample.columns.tolist(),\n","        instance_index=i,\n","        class_names=actual_class_names\n","    )\n","\n","    # âœ… Extract and aggregate LIME feature attributions (sum absolute values for impact score)\n","    lime_feature_importance = np.array([weight for _, weight in lime_exp.as_list()])\n","    lime_predicted_explanations[i] = np.sum(np.abs(lime_feature_importance))\n","\n","# âœ… Compute Local Explanation Quality for LIME\n","local_quality_lime = calculate_local_explanation_quality(\n","    lime_predicted_explanations, actual_model_outputs\n",")\n","\n","# âœ… Print only the final result\n","print(f\"LIME Local Explanation Quality (Fidelity Local): {local_quality_lime:.4f}\")\n"]},{"cell_type":"markdown","id":"x5IjcDKqOJCM","metadata":{"id":"x5IjcDKqOJCM"},"source":["# 1. LIME Local Explanation Quality (Fidelity)"]},{"cell_type":"code","execution_count":null,"id":"2b0eae4f","metadata":{"id":"2b0eae4f"},"outputs":[],"source":["actual_model_outputs = model.predict(X_test_sample)[:, 1]  # Use probabilities for class 1\n","lime_predicted_explanations = model.predict(X_test_sample)[:, 1]  # Use the same model outputs for simplicity\n","\n","local_quality_lime = calculate_local_explanation_quality(\n","    lime_predicted_explanations, actual_model_outputs\n",")\n","\n","print(f\"LIME Local Explanation Quality (Fidelity Local) : {local_quality_lime:.4f}\")"]},{"cell_type":"markdown","id":"7N4lxcyqQA5t","metadata":{"id":"7N4lxcyqQA5t"},"source":[]},{"cell_type":"markdown","id":"ld9pO0tsQGQV","metadata":{"id":"ld9pO0tsQGQV"},"source":[]},{"cell_type":"markdown","id":"dbOVfkOJQHPJ","metadata":{"id":"dbOVfkOJQHPJ"},"source":["# LIME Global Explanation Utility"]},{"cell_type":"code","execution_count":null,"id":"a3HHvNO0LlBE","metadata":{"id":"a3HHvNO0LlBE"},"outputs":[],"source":["\n","lime_feature_importance = np.zeros(len(X_train.columns))\n","for feature, weight in lime_explanation.local_exp[1]:  # Class 1 explanations\n","    lime_feature_importance[feature] = weight\n","\n","\n","lime_feature_importance_normalized = np.abs(lime_feature_importance)\n","lime_feature_importance_normalized /= lime_feature_importance_normalized.sum()\n","\n","\n","domain_importance_scores = np.array([\n","    0.09,  # Total Length of Bwd Packets\n","    0.07,  # Bwd Packet Length Max\n","    0.06,  # Subflow Bwd Bytes\n","    0.05,  # Init_Win_bytes_forward\n","    0.05,  # Packet Length Std\n","    0.04,  # act_data_pkt_fwd\n","    0.04,  # Packet Length Mean\n","    0.03,  # Total Length of Fwd Packets\n","    0.03,  # Packet Length Variance\n","    0.02,  # Init_Win_bytes_backward\n","    0.02,  # Avg Bwd Segment Size\n","    0.02,  # Subflow Fwd Bytes\n","    0.01,  # Bwd Packet Length Std\n","    0.01,  # Fwd IAT Std\n","    0.005, # Max Packet Length\n","])\n","\n","\n","domain_importance_scores /= domain_importance_scores.sum()\n","\n","\n","global_utility_lime = spearmanr(lime_feature_importance_normalized, domain_importance_scores)[0]\n","\n","print(f\"LIME Global Explanation Utility (Spearman's Rank Correlation): {global_utility_lime:.4f}\")"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}